<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>
<filter **>
  @type parser
  format json
  key_name log # docker stdout lines go to "log"
  # it's important try do a structured log on program terminate (non 0 exit)
  # so we get a parsable error! otherwise, we can't really search on it well.
  reserve_data true
</filter>
<match *.**>
  @type copy
  <store>
    buffer_type file
    buffer_path /fluentd/log/bigbuffs.*.buffer
    @type elasticsearch
    hosts http://elasticsearch:9200
    index_name fluentd
    flush_interval 5s
  </store>
  <store>
    @type stdout
  </store>
  <store>
    @type file
    @id output1
    path /fluentd/log/data.*.log
    symlink_path /fluentd/log/data.log
    append true
    time_slice_format %Y%m%d
    time_slice_wait 10m
    time_format %Y%m%dT%H%M%S%z
    buffer_path /fluentd/log/data.*.log
  </store>
</match>
